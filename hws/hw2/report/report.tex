\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\begin{document}


\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Universit√© Catholique de Louvain}\\[1.5cm] % Name of your university/college
\textsc{\Large Cloud Computing}\\[0.5cm] % Major heading such as course name
\textsc{\large LINGI2261}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Assignment 2 : Scaling Ribbit}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------



% If you don't want a supervisor, uncomment the two lines below and remove the section above
\Large \emph{Author:}\\
Eddy \textsc{Ndizera}\\
Ivan \textsc{Ahad} \\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[3cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

%\includegraphics{Logo}\\[1cm] % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\section{Explain the high level design of your solutions to the three scalability challenges of the application}

\subsection*{Frontend Scaling}

To use multiple cores on the machine, we forked clusters from one master cluster, as many clusters as there are cores on the CPU. By doing so, each slave cluster got its own core and its own load of data. This is an elegant way to scale the frontend as a new client is taken in charge by the less busy slave. \\



\subsection*{Timeline Scaling}

To scale the timeline, we used cassandra and the fanout on write model. This causes a lot of write when adding new data but the read becomes faster. We designed the database so that the data is easily accessed. We added 3 new tables, one for the timeline, and two to represents the edges (to indicate the relations between two accounts, see next section for more details). We didn't change the tweetable as we thought it was efficient like that. The timeline table contains the tweets that have to be shown for an account, this is done by putting for a specific account all of the tweets information with the author of each tweet (see next section). \\

By doing so, we store a lot of data, but when the user wants some information, the information easily accessed and fastly obtained. In fact, there can be improvements, such as partitioning the database so that the timeline geographically stores the tweets closer to the user.\\ 

Our write to the Cassandra Database is done by node.js. We know it isn't the best solution possible, as it would be better doing so with Kafka, as Kafka is relying, meaning there is no possible loss of data. However, as we will explain the the third section, we encountered issues using Kafka.

\subsection*{Analytics Scaling}
To implement an analytics top 10 of the most used hashtags in the tweets, we were going to use several technologies. We wanted to use Kafka, Spark and Memcached. First, Kafka sends all the different hashtags to Spark. Spark will then compute via an advanced MapReduce technique the ten most used hashtags, and sends the top 10 to be stored in Memcached. Memcached is used when the top 10 needs to be retrieved, as it is faster to get access to it than directly from the database. Since we focus on many writes and as few reads as possible, Cassandra was not the best option to store the top 10. 

\section{A description of your database design and data model. In particular, how did you decide to store user relations and tweets}
Here are the different database tables that we used for the project : 
\begin{itemize}
\item A table of users representing a user in general, with its full name and its username as primary key
\item A table containing all the tweets, with the ID of each of them, the author who wrote every tweet, a timestamp "created\_at" that tells when the tweet has been posted, and the message that the tweet contains. 
\item A table containing the timeline, that is all the tweets coming from all the users that an account follows. In opposition to the table of tweets, the primary key here is the username, corresponding to the current account for which all the tweets of all its users are in the timeline. It also contains the author of each tweet, the ID of the tweets, the timestamp, and the text.
\item A table called "Users\_src\_dest" that contains a source, and a destination. In this table, for each object in the table, a "src associated to a "dest" means that the destination is an account that follows the source, with the source-dest pair as primary key, since only the pair needs to be unique, the source might be duplicated but with a different destination. This table is very important to be able to retrieve all the followers of a particular account, just by using the username as a source.
\item Similarly, we created a table called "Users\_dest\_src" where a destination account follows a source account. It is useful to retrieve all the accounts that a particular is currently following. The primary key is a pair dest-source, for the same reason as the previous table. Those two last tables are the ones we used in particular to store the user relations.
\end{itemize}

\section{Describe the challenges you encountered, if any}
As we struggled finding two other members to be in a team of 4, every aspect of the project was a bit more challenging.\\

Our main challenge was to connect Kafka and Spark. We didn't manage to do so in time, as we tried to submit our assignment one day later to fix the problem but we still couldn't do it. Thus, the Analytics Scaling task isn't complete. 
\section{Describe how to run your application}

To run our application, you first have to run the kafka server on a localhost port 2181. You then have to load the database, by doing "nodejs loader.js". Afterwards, the database is filled, and you can run the app by doing "nodejs app.js". 

\end{document}